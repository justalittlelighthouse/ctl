# -*- coding: utf-8 -*-
"""Fee-Shifting Collab

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vrtn_rXM4sUD9buoMYBRxwwlQ1kBRjw4

# Collab for Extracting Data from OCRed PDFs Using Regex and LLMs

For instructions, please visit the following link: https://docs.google.com/document/d/1nxGGDE5Hw5U8yefoi4iJRVXRZFnBGs14-DbPBr9Rhyg/edit?usp=sharing
One can use this notebook to build a pipeline to parse and extract data from OCRed PDF files. _**Warning:** When using LLMs for entity extraction, be sure to perform extensive quality control. They are very susceptible to distracting language (latching on to text that sound "kind of like" what you're looking for) and missing language (making up content to fill any holes), and importantly, they do **NOT** provide any hints to when they may be erroring. You need to make sure random audits are part of your workflow!_ Below we've worked out a workflow using regular expressions and LLMs to parse data from zoning board orders, but the process is generalizable.

# Load Libraries


First we load the libraries we need. Note, if you try to run the cell, and you get something like `ModuleNotFoundError: No module named 'mod_name'`, you'll need to install the module. You can do this commentating the line below that reads `#!pip install mod_name` if it's listed. If it isn't, you can probably install it with a similarly formatted command.
"""

#!pip install os
!pip install PyPDF2
#!pip install re
#!pip install pandas
#!pip install numpy

!pip install transformers
!pip install openai==0.28
!pip install tiktoken

import os
from os import walk, path
import PyPDF2
import re
import pandas as pd
import numpy as np
import random

def read_pdf(file):
    try:
        pdfFile = PyPDF2.PdfReader(open(file, "rb"), strict=False)
        text = ""
        for page in pdfFile.pages:
            text += " " + page.extract_text()
        return text
    except:
        return ""

# Test Audio call
# Only works on Mac. If you aren't using a Mac, you should disable such calls below.
#tmp = os.system( "say Testing, testing, one, two, three.")
#del(tmp)

import json

from nltk.tokenize import word_tokenize, sent_tokenize

import openai
from transformers import GPT2TokenizerFast
tokenizer = GPT2TokenizerFast.from_pretrained("gpt2")

import tiktoken
ENCODING = "gpt2"
encoding = tiktoken.get_encoding(ENCODING)

def complete_text(prompt,temp=0,trys=0,clean=True):

    global tokens_used

    model="text-davinci-003"
    model_token_limit = 4097

    token_count = len(encoding.encode(prompt))
    max_tokens= model_token_limit-round(token_count+5)

    #try:
    response = openai.Completion.create(
      model=model,
      prompt=prompt,
      temperature=temp,
      max_tokens=max_tokens,
      top_p=1.0,
      frequency_penalty=0.0,
      presence_penalty=0.0
    )
    output = str(response["choices"][0]["text"].strip())
    #except:
    #    print("Problem with API call!")
    #    output = """{"output":"error"}"""

    tokens_used += token_count+len(encoding.encode(output))

    if clean:
        return clean_pseudo_json(output,temp=0,trys=trys)
    else:
        return output

def clean_pseudo_json(string,temp=0,key="output",trys=0,ask_for_help=1):
    try:
        output = json.loads(string)[key]
    except:
        try:
            string_4_json = re.findall("\{.*\}",re.sub("\n","",string))[0]
            output = json.loads(string_4_json)[key]
        except:
            try:
                string = "{"+string+"}"
                string_4_json = re.findall("\{.*\}",re.sub("\n","",string))[0]
                output = json.loads(string_4_json)[key]
            except Exception as e:
                prompt = "I tried to parse some json and got this error, '{}'. This was the would-be json.\n\n{}\n\nReformat it to fix the error.".format(e,string)
                if trys <= 3:
                    if trys == 0:
                        warm_up = 0
                    else:
                        warm_up = 0.25
                    output = complete_text(prompt,temp=0+warm_up,trys=trys+1)
                    print("\n"+str(output)+"\n")
                elif ask_for_help==1:
                    print(prompt+"\nReformaing FAILED!!!")
                    #try:
                    #    os.system( "say hey! I need some help. A little help please?")
                    #except:
                    #    print("'say' not supported.\n\n")
                    output = input("Let's see if we can avoid being derailed. Examine the above output and construct your own output text. Then enter it below. If the output needs to be something other than a string, e.g., a list or json, start it with `EVAL: `. If you're typing that, be very sure there's no malicious code in the output.\n")
                    if output[:6]=="EVAL: ":
                        output = eval(output[6:])
                else:
                    output = "There was an error getting a reponse!"

    return output

"""# Input OpenAI API Key & LLM settings

You'll need an API key to use an LLM. After creating an OpenAI account, you can create an API key here: https://platform.openai.com/account/api-keys

Enter your key between the quation marks next to `openai.api_key =` below, and run that cell.
"""

# Toggle LLM usage on or off
use_LLM = True

llm_temperature = 0 # I strongly suggest keeping the LLM's temp at zero to avoid it making things up.

openai.api_key = "" # <<--- REPLACE WITH YOUR KEY

"""# Load and parse files
Next, place a bunch of OCRed pdf files in the right folder (here, the `/content/gdrive/entity_extraction_sample_data/` folder). FWIW, you can use Adobe Pro to OCR in batch. Note: to make your files visisble at a location like that above, you'll need to add them to your Google Drive. E.g., you would need to copy https://drive.google.com/drive/folders/1H3bMgxzNxwxNL2YK6eMWt3nX985oBqVS?usp=sharing to your GDrive and name it `entity_extraction_sample_data` for it to be accessable at `/content/gdrive/entity_extraction_sample_data/`.
"""

# this mounts your google drive
from google.colab import drive
drive.mount('/content/gdrive')

df = pd.DataFrame() #this will create an empty dataframe

# list the files in the drive
filepath = "/content/gdrive/MyDrive/entity_extraction_sample_data/" # this is where we'll be looking for files
f = []
for (dirpath, dirnames, filenames) in walk(filepath): # create a list of file names
    f.extend(filenames)
    break

f #show list

sample = 4
#sample = len(f) #if you want to go through all the files, uncomment this line and comment out the above

token_counts = []
for file in random.choices(f,k=sample): # for each file in the list of file names, do some stuff

    tokens_used = 0

    column_names = ["file"]
    column_values = [file]

    fileloc = filepath+file
    text = read_pdf(fileloc)
    #print("text here: ", text)
    words = len(text.split())

    print("Parsing ~{} words ({} tokens) from: \"{}\"\n".format(words,len(encoding.encode(text)),fileloc))

    #############################################################
    # Here's where we use regex to pull out specific content

    try:
      # case Number
      # ---------------------------------------------------------
      case_no = re.search("(\d+-?\w+-?\d+)",text, flags=re.IGNORECASE).groups(0)[0].strip()
      column_names.append("case_no")
      column_values.append(case_no)
    except:
      column_names.append("case_no")
      column_values.append("NA")

 ############################################################################
     # Here's where use GPT to pull out some specific content.

    #
    # Note: You should consider combining multiple prompts into a single prompt
    # to avoid making unnecessary api calls. See e.g. Reasoning & Decision below
    #

    if use_LLM:

      #try:
        # ---------------------------------------------------------
        # description of variance requested
        # ---------------------------------------------------------
      prompt_text = """Below you will be provided with the text of an order for judgment from housing court. You're looking to find the amount of fees awarded, in dollars, to the attorney. That is, the amount of money that the court said the opposing party had to pay.

  Here's the text of the order.

  {}


  Return a json object, including the outermost curly brackets, where the key is "output" and the value is the dollar amount of award. If no dollar amount of award in the text, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
      #print(prompt_text)

      award = complete_text(prompt_text,temp=llm_temperature)
      column_names.append("award")
      column_values.append(award)
      #except:
        #column_names.append("request")
        #column_values.append("NA")

    if use_LLM:

          #try:
            # ---------------------------------------------------------
            # description of variance requested
            # ---------------------------------------------------------
          prompt_text = """Below you will be provided with the text of an order for judgment from housing court. You're looking to find the name of the attorney and which party they represent (plaintiff or defendant).

          Here's the text of the order.

      {}

 Return a json object, including the outermost curly brackets, where the key is "output" and the value is the name of the attorney and the party they represent. If you can't find the attorney, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
      #print(prompt_text)
    attorney = complete_text(prompt_text,temp=llm_temperature)
    column_names.append("attorney")
    column_values.append(attorney)
      #except:
        #column_names.append("request")
        #column_values.append("NA")

    if use_LLM:

          #try:
            # ---------------------------------------------------------
            # description of variance requested
            # ---------------------------------------------------------
          prompt_text = """Below you will be provided with the text of an order for judgment from housing court. From the text, give a summary of the reasoning given for the judge's decision.

          Here's the text of the order.

      {}

 Return a json object, including the outermost curly brackets, where the key is "output" and the value is the summary of the judge's reasoning. If you can't create a summary, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
      #print(prompt_text)
    summary = complete_text(prompt_text,temp=llm_temperature)
    column_names.append("summary")
    column_values.append(summary)
      #except:
        #column_names.append("request")
        #column_values.append("NA")

    if use_LLM:

          #try:
            # ---------------------------------------------------------
            # description of variance requested
            # ---------------------------------------------------------
          prompt_text = """Below you will be provided with the text of an order for judgment from housing court. From the text, pull the judge's name (this should be a full name, not just "Associate Justice").

          Here's the text of the order.

      {}

 Return a json object, including the outermost curly brackets, where the key is "output" and the value is the judge's name. If you can't find the judge's full name, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
      #print(prompt_text)
    Judgename = complete_text(prompt_text,temp=llm_temperature)
    column_names.append("Judgename")
    column_values.append(Judgename)
      #except:
        #column_names.append("request")
        #column_values.append("NA")

    if use_LLM:

          #try:
            # ---------------------------------------------------------
            # description of variance requested
            # ---------------------------------------------------------
          prompt_text = """Below you will be provided with the text of an order for judgment from housing court. From the text, find out if the Judge mentioned the Lodestar method, and if so, summarize what they said about it.

          Here's the text of the order.

      {}

 Return a json object, including the outermost curly brackets, where the key is "output" and the value is a summary about what was said about the Lodestar method. If you can't find anything about the Lodestae, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
      #print(prompt_text)
    Lodestar = complete_text(prompt_text,temp=llm_temperature)
    column_names.append("Lodestar")
    column_values.append(Lodestar)
      #except:
        #column_names.append("request")
        #column_values.append("NA")


    if use_LLM:

          #try:
            # ---------------------------------------------------------
            # description of variance requested
            # ---------------------------------------------------------
          prompt_text = """Below you will be provided with the text of an order for judgment from housing court. From the text, pull the defendant's full name.

          Here's the text of the order.

      {}

 Return a json object, including the outermost curly brackets, where the key is "output" and the value is the defendant's name. If you can't find the judge's full name, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
      #print(prompt_text)
    Defendantname = complete_text(prompt_text,temp=llm_temperature)
    column_names.append("Defendantname")
    column_values.append(Defendantname)
      #except:
        #column_names.append("request")
        #column_values.append("NA")


    if use_LLM:

          #try:
            # ---------------------------------------------------------
            # description of variance requested
            # ---------------------------------------------------------
          prompt_text = """Below you will be provided with the text of an order for judgment from housing court. From the text, pull the plaintiff's name.

          Here's the text of the order.

      {}

 Return a json object, including the outermost curly brackets, where the key is "output" and the value is the plaintiff's name. If you can't find the plaintiff's full name, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
      #print(prompt_text)
    Plaintiffname = complete_text(prompt_text,temp=llm_temperature)
    column_names.append("Plaintiffname")
    column_values.append(Plaintiffname)
      #except:
        #column_names.append("request")
        #column_values.append("NA")


    if use_LLM:

          #try:
            # ---------------------------------------------------------
            # description of variance requested
            # ---------------------------------------------------------
          prompt_text = """Below you will be provided with the text of an order for judgment from housing court. You're looking to find the number of hours the attorney worked and hourly rate/fee they charged.

          Here's the text of the order.

      {}


      Return a json object, including the outermost curly brackets, where the key is "output" and the value is the amount of hours the attorney worked, and their fee (separate by commas). If you can't find an hour amount in the text of the above, answer "none found". Be sure to use valid json, encasing keys and values in double quotes, and escaping internal quotes and special characters as needed.""". format(text)
    #print(prompt_text)
    hours_and_rate = complete_text(prompt_text,temp=llm_temperature)
    column_names.append("hours_and_rate")
    column_values.append(hours_and_rate)
    #except:
      #column_names.append("request")
      #column_values.append("NA")


    #############################################################

    # After testing or when working with large numbers, you may want to comment this next bit out

    # Show your work
    i = 0
    for datum in column_values:
        print("{}: {}\n".format(column_names[i].upper(),datum))
        i+=1


    # Show cost per run
    if use_LLM:
        print("Tokens used (approx.): {} (API Cost ~${})\n".format(tokens_used,tokens_used*(0.002/1000))) # See https://openai.com/pricing
        token_counts.append(tokens_used)

    print("================================================\n")

    df = pd.concat([df,pd.DataFrame([column_values],columns=column_names)], ignore_index=True,sort=False)

print("Average approx. tokens used per item {} (API Cost ~${})\n".format(np.array(token_counts).mean(),np.array(token_counts).mean()*(0.002/1000))) # See https://openai.com/pricing

display(df)



# If you're happy with the stuff you pulled out above, you can write the df to a csv file
# make sure the path is placing it where you want it!

df.to_csv("/content/gdrive/MyDrive/CodingLawFinalProjectSheet2023.csv", index=False, encoding="utf-8")

